{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "q:\\Projects\\Multimodal-Jarvis\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import gradio as gr\n",
    "from time import sleep\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T05:59:13.345927Z",
     "start_time": "2025-03-21T05:58:07.551946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "def echo(text, request: gr.Request):\n",
    "    if request:\n",
    "        print(\"Request headers dictionary:\", request.headers)\n",
    "        print(\"IP address:\", request.client.host)\n",
    "        print(\"Query parameters:\", dict(request.query_params))\n",
    "    return text\n",
    "\n",
    "io = gr.Interface(echo, \"textbox\", \"textbox\").launch(share=True, debug=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://cb6664424ed5f6663a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://cb6664424ed5f6663a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request headers dictionary: Headers({'host': 'cb6664424ed5f6663a.gradio.live', 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'content-length': '94', 'accept': '*/*', 'accept-encoding': 'gzip, deflate, br, zstd', 'accept-language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7,uk;q=0.6', 'content-type': 'application/json', 'dnt': '1', 'origin': 'https://cb6664424ed5f6663a.gradio.live', 'priority': 'u=1, i', 'referer': 'https://cb6664424ed5f6663a.gradio.live/', 'sec-ch-ua': '\"Chromium\";v=\"134\", \"Not:A-Brand\";v=\"24\", \"Google Chrome\";v=\"134\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': '\"Windows\"', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'same-origin', 'x-amzn-trace-id': 'Root=1-67dd0011-3877bceb42fe855346916663', 'x-forwarded-for': '104.28.201.202, 172.31.56.254', 'x-forwarded-port': '443', 'x-forwarded-proto': 'https'})\n",
      "IP address: 172.31.56.254\n",
      "Query parameters: {}\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://d94524aa5d1c37d8cb.gradio.live\n",
      "Killing tunnel 127.0.0.1:7862 <> https://cb6664424ed5f6663a.gradio.live\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:09:20,995 - INFO - Logging is set up!\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Change to DEBUG for more details\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(r\"Q:\\Projects\\Multimodal-Jarvis\\data\\logs\\app.log\"),  # Save logs to a file\n",
    "        logging.StreamHandler()  # Show logs in the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Logging is set up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mnotebook controller is DISPOSED. \n",
      "\u001B[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# https://www.gradio.app/guides/theming-guide\n",
    "# https://huggingface.co/spaces/gstaff/xkcd/blob/main/app.py\n",
    "# test_theme = gr.Theme.from_hub(\"gstaff/xkcd\")\n",
    "# gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;31mInit signature:\u001B[0m\n",
      "\u001B[0mgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTabItem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0mlabel\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'str | None'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0mvisible\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'bool'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0minteractive\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'bool'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[1;33m*\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0mid\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'int | str | None'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0melem_id\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'str | None'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0melem_classes\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'list[str] | str | None'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0mscale\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'int'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m    \u001B[0mrender\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m'bool'\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\n",
      "\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mDocstring:\u001B[0m     \n",
      "Tab (or its alias TabItem) is a layout element. Components defined within the Tab will be visible when this tab is selected tab.\n",
      "Example:\n",
      "    with gr.Blocks() as demo:\n",
      "        with gr.Tab(\"Lion\"):\n",
      "            gr.Image(\"lion.jpg\")\n",
      "            gr.Button(\"New Lion\")\n",
      "        with gr.Tab(\"Tiger\"):\n",
      "            gr.Image(\"tiger.jpg\")\n",
      "            gr.Button(\"New Tiger\")\n",
      "Guides: controlling-layout\n",
      "\u001B[1;31mInit docstring:\u001B[0m\n",
      "Parameters:\n",
      "    label: The visual label for the tab\n",
      "    id: An optional identifier for the tab, required if you wish to control the selected tab from a predict function.\n",
      "    elem_id: An optional string that is assigned as the id of the <div> containing the contents of the Tab layout. The same string followed by \"-button\" is attached to the Tab button. Can be used for targeting CSS styles.\n",
      "    elem_classes: An optional string or list of strings that are assigned as the class of this component in the HTML DOM. Can be used for targeting CSS styles.\n",
      "    render: If False, this layout will not be rendered in the Blocks context. Should be used if the intention is to assign event listeners now but render the component later.\n",
      "    scale: relative size compared to adjacent elements. 1 or greater indicates the Tab will expand in size.\n",
      "    visible: If False, Tab will be hidden.\n",
      "    interactive: If False, Tab will not be clickable.\n",
      "\u001B[1;31mFile:\u001B[0m           q:\\minianaconda\\envs\\ml\\lib\\site-packages\\gradio\\layouts\\tabs.py\n",
      "\u001B[1;31mType:\u001B[0m           ComponentMeta\n",
      "\u001B[1;31mSubclasses:\u001B[0m     "
     ]
    }
   ],
   "source": [
    "gr.TabItem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = gr.themes.Default(\n",
    "    font=['Noto Sans', 'Helvetica', 'ui-sans-serif', 'system-ui', 'sans-serif'],\n",
    "    font_mono=['IBM Plex Mono', 'ui-monospace', 'Consolas', 'monospace'],\n",
    ").set(\n",
    "    border_color_primary='#c5c5d2',\n",
    "    button_large_padding='6px 12px',\n",
    "    body_text_color_subdued='#484848',\n",
    "    background_fill_secondary='#eaeaea',\n",
    "    background_fill_primary='var(--neutral-50)',\n",
    "    body_background_fill=\"white\",\n",
    "    block_background_fill=\"#f4f4f4\",\n",
    "    body_text_color=\"#333\",\n",
    "    button_secondary_background_fill=\"#f4f4f4\",\n",
    "    button_secondary_border_color=\"var(--border-color-primary)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Device set to use cpu\n",
      "2025-02-03 16:19:13,778 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-03 16:19:13,802 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 16:19:14,122 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n",
      "2025-02-03 16:19:14,122 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170CD5EF50>\n",
      "2025-02-03 16:19:14,232 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002170CC2C640> server_hostname='api.gradio.app' timeout=3\n",
      "2025-02-03 16:19:14,441 - DEBUG - Using selector: SelectSelector\n",
      "2025-02-03 16:19:14,465 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
      "2025-02-03 16:19:14,467 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170CFB1000>\n",
      "2025-02-03 16:19:14,468 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,472 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:14,473 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,474 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:14,475 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,477 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Mon, 03 Feb 2025 14:19:14 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "2025-02-03 16:19:14,478 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:14,480 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,482 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:14,483 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:14,484 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:14,486 - DEBUG - close.started\n",
      "2025-02-03 16:19:14,488 - DEBUG - close.complete\n",
      "2025-02-03 16:19:14,490 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
      "2025-02-03 16:19:14,493 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170CFB2200>\n",
      "2025-02-03 16:19:14,495 - DEBUG - send_request_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:14,497 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:14,498 - DEBUG - send_request_body.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:14,502 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:14,515 - DEBUG - receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:14,519 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Mon, 03 Feb 2025 14:19:14 GMT'), (b'server', b'uvicorn'), (b'content-length', b'72714'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "2025-02-03 16:19:14,522 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:14,523 - DEBUG - receive_response_body.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:14,525 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:14,527 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:14,528 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:14,530 - DEBUG - close.started\n",
      "2025-02-03 16:19:14,533 - DEBUG - close.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "Monitoring URL: http://127.0.0.1:7860/monitoring/wQA_QSM6iPiclgqjEEHN2w\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 16:19:14,540 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-03 16:19:14,673 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170CC611E0>\n",
      "2025-02-03 16:19:14,675 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,677 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:14,678 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,679 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:14,682 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,755 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/1.1\" 200 0\n",
      "2025-02-03 16:19:14,887 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Feb 2025 14:19:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-02-03 16:19:14,889 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:14,891 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:14,892 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:14,892 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:14,894 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:14,895 - DEBUG - close.started\n",
      "2025-02-03 16:19:14,896 - DEBUG - close.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "def enable_input():\n",
    "    return gr.update(interactive=True)\n",
    "\n",
    "def print_like_dislike(x: gr.LikeData):\n",
    "    print(x.index, x.value, x.liked)\n",
    "\n",
    "def handle_undo(history: list[gr.ChatMessage], undo_data: gr.UndoData) -> tuple[list[gr.ChatMessage], str]:\n",
    "    return history[:undo_data.index], history[undo_data.index].content \n",
    "\n",
    "\n",
    "def handle_edit(history: list[gr.ChatMessage], edit_data: gr.EditData) -> list[gr.ChatMessage]:\n",
    "    new_history = history[:edit_data.index]\n",
    "    new_history[-1].content = edit_data.value  \n",
    "    return new_history\n",
    "\n",
    "\n",
    "def add_message(history, message):\n",
    "    if message[\"text\"] is not None:\n",
    "      history.append(gr.ChatMessage(role = \"user\", content = message[\"text\"])) \n",
    "\n",
    "    for file_path in message[\"files\"]:\n",
    "        if file_path.endswith(\".wav\"):\n",
    "            transcribed_text = audiofile_to_text(file_path)\n",
    "            history.append(gr.ChatMessage(role = \"user\", content = transcribed_text))\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "def bot_output(history: list):\n",
    "    try:\n",
    "        history.append(gr.ChatMessage(role=\"assistant\", content=\"\"))\n",
    "        \n",
    "        text = tokenizer.apply_chat_template(\n",
    "            history,    # [msg.dict() for msg in history]\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        model_inputs  = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "        generated_text  = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        if not generated_text or not isinstance(generated_text, str):  \n",
    "            generated_text = \"I'm sorry, but I couldn't generate a response.\"\n",
    "\n",
    "        for char in generated_text :\n",
    "            history[-1].content += char\n",
    "            sleep(0.05) \n",
    "            yield history\n",
    "\n",
    "        history = text_to_audiofile(generated_text, history)\n",
    "        yield history\n",
    "    except Exception as e:\n",
    "        history.append(gr.ChatMessage(role=\"system\", content=f\"Failed to create text: {str(e)}\"))\n",
    "        yield history\n",
    "        raise gr.Error(f\"Failed to create text: {str(e)}\")\n",
    "\n",
    "def audiofile_to_text(wav_path):\n",
    "    try:\n",
    "        sample_rate, audio_data = wavfile.read(wav_path)\n",
    "        audio_data = np.array(audio_data, dtype=np.float32)\n",
    "        audio_data /= np.max(np.abs(audio_data))\n",
    "        \n",
    "        transcribed_text = transcriber_model({\"raw\": audio_data, \"sampling_rate\": sample_rate})[\"text\"]\n",
    "        return str(transcribed_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Failed to transcribe audio: {e}\")\n",
    "\n",
    "def text_to_audiofile(input_text, history):\n",
    "    try:\n",
    "        speech = synthesiser(input_text, forward_params = {\"do_sample\": True})\n",
    "        rate_speech = speech[\"sampling_rate\"]\n",
    "        data_speech = speech[\"audio\"]\n",
    "        data_speech = data_speech.flatten()\n",
    "        data_speech = np.int16(data_speech / np.max(np.abs(data_speech)) * 32767)\n",
    "\n",
    "        wavfile.write(r\"/src/data/audio\\bark_out.wav\", rate=rate_speech, data=data_speech)\n",
    "        history.append(gr.ChatMessage(role=\"assistant\", content= \n",
    "            gr.Audio(r\"/src/data/audio\\bark_out.wav\"),\n",
    "                                      metadata={\"title\": rf\"üõ†Ô∏è Used tool {model_name_tts}\"}))\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Failed to convert text to audio: {e}\")\n",
    "\n",
    "model_name_nlp = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\nlp\\Qwen2.5-1.5B-Instruct\"\n",
    "model_name_stt = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\stt\\whisper-large-v3-turbo\"\n",
    "model_name_tts = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\tts\\Suno-Bark\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_nlp)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_nlp, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "transcriber_model = pipeline(\"automatic-speech-recognition\", model = model_name_stt)\n",
    "synthesiser = pipeline(\"text-to-speech\", model = model_name_tts)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} for inference\")\n",
    "\n",
    "\n",
    "# callback = gr.CSVLogger()\n",
    "def bot_ui():\n",
    "    with gr.Blocks(theme=theme) as blocks:\n",
    "        blocks.analytics_enabled = True\n",
    "        gr.Markdown(\n",
    "        f\"\"\"\n",
    "        # {\" \".join(os.path.basename(model_name_nlp).split(\"-\"))} Test\n",
    "        \"\"\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=10):\n",
    "                chatbot = gr.Chatbot(elem_id=\"chatbot\", \n",
    "                    height=500,\n",
    "                    type=\"messages\",\n",
    "                    bubble_full_width=False,\n",
    "                    placeholder=f\"<strong><br><big>JARvis</strong>\",\n",
    "                    editable=True\n",
    "                )\n",
    "\n",
    "                chat_input  = gr.MultimodalTextbox(\n",
    "                    interactive=True,\n",
    "                    file_count=\"multiple\",\n",
    "                    placeholder=\"Ask me a question\",\n",
    "                    container=False,\n",
    "                    show_label=False,\n",
    "                    sources=[\"microphone\", \"upload\"],\n",
    "                )\n",
    "\n",
    "                chat_msg = chat_input.submit(\n",
    "                    add_message, [chatbot, chat_input], [chatbot, chat_input]\n",
    "                )\n",
    "                # callback.setup([chat_msg, chat_input], \"chat_messages.csv\")\n",
    "\n",
    "                bot_msg = chat_msg.then(bot_output, chatbot, chatbot, api_name=\"bot_response\")\n",
    "                bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input], concurrency_limit = 40)\n",
    "\n",
    "                chatbot.like(print_like_dislike, None, None)\n",
    "                chatbot.edit(handle_edit, chatbot, chatbot)\n",
    "                chatbot.undo(handle_undo, chatbot, [chatbot, chat_input])\n",
    "    return blocks\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = bot_ui()\n",
    "    demo.queue(api_open=False)\n",
    "    demo.launch(show_error=True, \n",
    "                show_api=True, \n",
    "                debug=True, \n",
    "                allowed_paths = [r\"Q:\\Projects\\Multimodal-Jarvis\\data\\audio\"],\n",
    "                enable_monitoring=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:50:16,047 - WARNING - Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Device set to use cpu\n",
      "2025-02-06 17:50:19,086 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-06 17:50:19,130 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2025-02-06 17:50:19,256 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:50:19,270 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2025-02-06 17:50:19,549 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n",
      "2025-02-06 17:50:19,581 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001515E8605B0>\n",
      "2025-02-06 17:50:19,613 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001515E71A540> server_hostname='api.gradio.app' timeout=3\n",
      "2025-02-06 17:50:19,673 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001515E7033A0>\n",
      "2025-02-06 17:50:19,709 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001515E719840> server_hostname='api.gradio.app' timeout=3\n",
      "2025-02-06 17:50:19,772 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n",
      "2025-02-06 17:50:20,076 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000151603A3C40>\n",
      "2025-02-06 17:50:20,083 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,087 - DEBUG - send_request_headers.complete\n",
      "2025-02-06 17:50:20,093 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,093 - DEBUG - send_request_body.complete\n",
      "2025-02-06 17:50:20,105 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,223 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001515E703CD0>\n",
      "2025-02-06 17:50:20,223 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,235 - DEBUG - send_request_headers.complete\n",
      "2025-02-06 17:50:20,238 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,245 - DEBUG - send_request_body.complete\n",
      "2025-02-06 17:50:20,246 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,303 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 06 Feb 2025 15:50:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-02-06 17:50:20,316 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 17:50:20,321 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,327 - DEBUG - receive_response_body.complete\n",
      "2025-02-06 17:50:20,338 - DEBUG - response_closed.started\n",
      "2025-02-06 17:50:20,343 - DEBUG - response_closed.complete\n",
      "2025-02-06 17:50:20,351 - DEBUG - close.started\n",
      "2025-02-06 17:50:20,359 - DEBUG - close.complete\n",
      "2025-02-06 17:50:20,453 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 06 Feb 2025 15:50:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-02-06 17:50:20,453 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 17:50:20,462 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:20,463 - DEBUG - receive_response_body.complete\n",
      "2025-02-06 17:50:20,469 - DEBUG - response_closed.started\n",
      "2025-02-06 17:50:20,473 - DEBUG - response_closed.complete\n",
      "2025-02-06 17:50:20,480 - DEBUG - close.started\n",
      "2025-02-06 17:50:20,487 - DEBUG - close.complete\n",
      "2025-02-06 17:50:21,001 - DEBUG - Using selector: SelectSelector\n",
      "2025-02-06 17:50:21,024 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
      "2025-02-06 17:50:21,028 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001515EF9A230>\n",
      "2025-02-06 17:50:21,029 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:21,030 - DEBUG - send_request_headers.complete\n",
      "2025-02-06 17:50:21,032 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:21,033 - DEBUG - send_request_body.complete\n",
      "2025-02-06 17:50:21,034 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:21,035 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Thu, 06 Feb 2025 15:50:21 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "2025-02-06 17:50:21,037 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 17:50:21,038 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-06 17:50:21,039 - DEBUG - receive_response_body.complete\n",
      "2025-02-06 17:50:21,040 - DEBUG - response_closed.started\n",
      "2025-02-06 17:50:21,040 - DEBUG - response_closed.complete\n",
      "2025-02-06 17:50:21,042 - DEBUG - close.started\n",
      "2025-02-06 17:50:21,044 - DEBUG - close.complete\n",
      "2025-02-06 17:50:21,046 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
      "2025-02-06 17:50:21,049 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001515F9F81C0>\n",
      "2025-02-06 17:50:21,051 - DEBUG - send_request_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-06 17:50:21,053 - DEBUG - send_request_headers.complete\n",
      "2025-02-06 17:50:21,056 - DEBUG - send_request_body.started request=<Request [b'HEAD']>\n",
      "2025-02-06 17:50:21,071 - DEBUG - send_request_body.complete\n",
      "2025-02-06 17:50:21,072 - DEBUG - receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-06 17:50:21,074 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Thu, 06 Feb 2025 15:50:21 GMT'), (b'server', b'uvicorn'), (b'content-length', b'59319'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "2025-02-06 17:50:21,075 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 17:50:21,076 - DEBUG - receive_response_body.started request=<Request [b'HEAD']>\n",
      "2025-02-06 17:50:21,078 - DEBUG - receive_response_body.complete\n",
      "2025-02-06 17:50:21,079 - DEBUG - response_closed.started\n",
      "2025-02-06 17:50:21,080 - DEBUG - response_closed.complete\n",
      "2025-02-06 17:50:21,081 - DEBUG - close.started\n",
      "2025-02-06 17:50:21,083 - DEBUG - close.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "Monitoring URL: http://127.0.0.1:7860/monitoring/RLPB9INg5i1V1ffxtrfBRw\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:50:21,090 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-06 17:50:21,394 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/1.1\" 200 0\n",
      "2025-02-06 17:50:31,918 - DEBUG - Calling on_part_begin with no data\n",
      "2025-02-06 17:50:31,919 - DEBUG - Calling on_header_field with data[42:61]\n",
      "2025-02-06 17:50:31,925 - DEBUG - Calling on_header_value with data[63:108]\n",
      "2025-02-06 17:50:31,926 - DEBUG - Calling on_header_end with no data\n",
      "2025-02-06 17:50:31,928 - DEBUG - Calling on_header_field with data[110:122]\n",
      "2025-02-06 17:50:31,929 - DEBUG - Calling on_header_value with data[124:148]\n",
      "2025-02-06 17:50:31,931 - DEBUG - Calling on_header_end with no data\n",
      "2025-02-06 17:50:31,933 - DEBUG - Calling on_headers_finished with no data\n",
      "2025-02-06 17:50:31,938 - DEBUG - Calling on_part_data with data[152:212992]\n",
      "2025-02-06 17:50:31,943 - DEBUG - Calling on_part_data with data[0:30634]\n",
      "2025-02-06 17:50:31,945 - DEBUG - Calling on_part_end with no data\n",
      "2025-02-06 17:50:31,947 - DEBUG - Calling on_end with no data\n",
      "2025-02-06 17:50:31,978 - DEBUG - Calling on_part_begin with no data\n",
      "2025-02-06 17:50:31,980 - DEBUG - Calling on_header_field with data[42:61]\n",
      "2025-02-06 17:50:31,981 - DEBUG - Calling on_header_value with data[63:108]\n",
      "2025-02-06 17:50:31,983 - DEBUG - Calling on_header_end with no data\n",
      "2025-02-06 17:50:31,984 - DEBUG - Calling on_header_field with data[110:122]\n",
      "2025-02-06 17:50:31,985 - DEBUG - Calling on_header_value with data[124:148]\n",
      "2025-02-06 17:50:31,987 - DEBUG - Calling on_header_end with no data\n",
      "2025-02-06 17:50:31,989 - DEBUG - Calling on_headers_finished with no data\n",
      "2025-02-06 17:50:31,991 - DEBUG - Calling on_part_data with data[152:243626]\n",
      "2025-02-06 17:50:31,991 - DEBUG - Calling on_part_end with no data\n",
      "2025-02-06 17:50:31,993 - DEBUG - Calling on_end with no data\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 324, in jsonable_encoder\n",
      "    data = dict(obj)\n",
      "TypeError: cannot convert dictionary update sequence element #0 to a sequence\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 329, in jsonable_encoder\n",
      "    data = vars(obj)\n",
      "TypeError: vars() argument must have __dict__ attribute\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\route_utils.py\", line 795, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\route_utils.py\", line 811, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\starlette\\routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\routing.py\", line 327, in app\n",
      "    content = await serialize_response(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\routing.py\", line 201, in serialize_response\n",
      "    return jsonable_encoder(response_content)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 303, in jsonable_encoder\n",
      "    jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 303, in jsonable_encoder\n",
      "    jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 303, in jsonable_encoder\n",
      "    jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 333, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 303, in jsonable_encoder\n",
      "    jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 303, in jsonable_encoder\n",
      "    jsonable_encoder(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\fastapi\\encoders.py\", line 332, in jsonable_encoder\n",
      "    raise ValueError(errors) from e\n",
      "ValueError: [TypeError('cannot convert dictionary update sequence element #0 to a sequence'), TypeError('vars() argument must have __dict__ attribute')]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11888\\2847510476.py\", line 72, in bot_output\n",
      "    text = tokenizer.apply_chat_template(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1683, in apply_chat_template\n",
      "    rendered_chat = compiled_template.render(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\jinja2\\environment.py\", line 1295, in render\n",
      "    self.environment.handle_exception()\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\jinja2\\environment.py\", line 942, in handle_exception\n",
      "    raise rewrite_traceback_stack(source=source)\n",
      "  File \"<template>\", line 23, in top-level template code\n",
      "TypeError: can only concatenate str (not \"tuple\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\blocks.py\", line 2044, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\blocks.py\", line 1603, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 833, in asyncgen_wrapper\n",
      "    response = await iterator.__anext__()\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\chat_interface.py\", line 898, in _stream_fn\n",
      "    first_response = await utils.async_iteration(generator)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 722, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 705, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11888\\2847510476.py\", line 95, in bot_output\n",
      "    raise gr.Error(f\"Failed to create text: {str(e)}\")\n",
      "gradio.exceptions.Error: 'Failed to create text: can only concatenate str (not \"tuple\") to str'\n",
      "Traceback (most recent call last):\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\routes.py\", line 993, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\blocks.py\", line 2044, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\blocks.py\", line 1591, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py\", line 883, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\chat_interface.py\", line 468, in _save_conversation\n",
      "    saved_conversations[index] = conversation\n",
      "IndexError: list assignment index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import gradio as gr\n",
    "from time import sleep\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import wavfile\n",
    "\n",
    "model_name_nlp = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\nlp\\Qwen2.5-1.5B-Instruct\"\n",
    "model_name_stt = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\stt\\whisper-large-v3-turbo\"\n",
    "model_name_tts = r\"Q:\\Projects\\Multimodal-Jarvis\\models\\tts\\Suno-Bark\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_nlp)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_nlp,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "transcriber_model = pipeline(\"automatic-speech-recognition\", model = model_name_stt)\n",
    "synthesiser = pipeline(\"text-to-speech\", model = model_name_tts)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} for inference\")\n",
    "\n",
    "def audiofile_to_text(wav_path):\n",
    "    try:\n",
    "        sample_rate, audio_data = wavfile.read(wav_path)\n",
    "        audio_data = np.array(audio_data, dtype=np.float32)\n",
    "        audio_data /= np.max(np.abs(audio_data))\n",
    "        \n",
    "        transcribed_text = transcriber_model({\"raw\": audio_data, \"sampling_rate\": sample_rate})[\"text\"]\n",
    "        return str(transcribed_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Failed to transcribe audio: {e}\")\n",
    "\n",
    "def text_to_audiofile(input_text, history):\n",
    "    try:\n",
    "        speech = synthesiser(input_text, forward_params = {\"do_sample\": True})\n",
    "        rate_speech = speech[\"sampling_rate\"]\n",
    "        data_speech = speech[\"audio\"]\n",
    "        data_speech = data_speech.flatten()\n",
    "        data_speech = np.int16(data_speech / np.max(np.abs(data_speech)) * 32767)\n",
    "\n",
    "        wavfile.write(r\"/src/data/audio\\bark_out.wav\", rate=rate_speech, data=data_speech)\n",
    "        history.append(gr.ChatMessage(role=\"assistant\", content= \n",
    "            gr.Audio(r\"/src/data/audio\\bark_out.wav\"),\n",
    "                                      metadata={\"title\": rf\"üõ†Ô∏è Used tool {model_name_tts}\"}))\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Failed to convert text to audio: {e}\")\n",
    "\n",
    "\n",
    "def bot_output(message, history: list):\n",
    "    try:\n",
    "        output_history = [] # append transcribed text to output_history\n",
    "\n",
    "        for file_path in message[\"files\"]:\n",
    "            try:\n",
    "                transcribed_text = audiofile_to_text(file_path)\n",
    "                history.append(gr.ChatMessage(role=\"user\", content=transcribed_text))\n",
    "                output_history.append(gr.ChatMessage(role=\"assistant\", content=f\"**{transcribed_text}**\"))\n",
    "\n",
    "            except Exception as transcription_error:\n",
    "                print(f\"Error transcribing {file_path}: {transcription_error}\")\n",
    "                history.append(gr.ChatMessage(role=\"assistant\", \n",
    "                                                content=f\"Failed to transcribe {file_path}\"))\n",
    "           \n",
    "        output_history.append(gr.ChatMessage(role=\"assistant\", content=\"\"))\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            history,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        model_inputs  = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "        generated_text  = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        if not generated_text or not isinstance(generated_text, str):  \n",
    "            generated_text = \"I'm sorry, but I couldn't generate a response.\"\n",
    "\n",
    "        for char in generated_text :\n",
    "            output_history[-1].content += char\n",
    "            sleep(0.01) \n",
    "            yield output_history\n",
    "\n",
    "        output_history = text_to_audiofile(generated_text, output_history)\n",
    "        yield output_history\n",
    "\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Failed to create text: {str(e)}\")\n",
    "\n",
    "def chat_ui():\n",
    "    with gr.Blocks(theme=theme) as blocks:\n",
    "        gr.Markdown(\n",
    "            f\"\"\"\n",
    "            # {\" \".join(os.path.basename(model_name_nlp).split(\"-\"))} Test\n",
    "            \"\"\")\n",
    "        gr.ChatInterface(\n",
    "            bot_output,\n",
    "            api_name = \"chat\",\n",
    "            editable=True,\n",
    "            theme=theme,\n",
    "            type=\"messages\",\n",
    "            flagging_mode = 'manual',\n",
    "            save_history=True,\n",
    "\n",
    "            chatbot = gr.Chatbot(elem_id=\"chatbot\", \n",
    "                        height=500,\n",
    "                        type=\"messages\",\n",
    "                        placeholder=f\"<strong><br><big>JARvis</strong>\",\n",
    "                        editable=True\n",
    "                    ),\n",
    "            textbox = gr.MultimodalTextbox(\n",
    "                        interactive=True,\n",
    "                        file_count=\"multiple\",\n",
    "                        container=False,\n",
    "                        show_label=False,\n",
    "                        placeholder=\"Ask me a question\",\n",
    "                        sources=[\"microphone\", \"upload\"],\n",
    "                    ),\n",
    "        )\n",
    "        return blocks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_ui().queue().launch(\n",
    "        show_error=True, \n",
    "        show_api=True, \n",
    "        debug=True, \n",
    "        allowed_paths = [r\"Q:\\Projects\\Multimodal-Jarvis\\data\\audio\"],\n",
    "        enable_monitoring=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mnotebook controller is DISPOSED. \n",
      "\u001B[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_chat_ui():\n",
    "    blocks = gr.Blocks()\n",
    "    with blocks:\n",
    "        gr.Markdown(\n",
    "        f\"\"\"\n",
    "        # {\" \".join(os.path.basename(model_name_nlp).split(\"-\"))} Test\n",
    "        \"\"\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=10):\n",
    "                chatbot = gr.Chatbot(elem_id=\"chatbot\", \n",
    "                    height=500,\n",
    "                    type=\"messages\",\n",
    "                    bubble_full_width=False,\n",
    "                    placeholder=f\"<strong><br><big>JARvis</strong>\",\n",
    "                    editable=True\n",
    "                )\n",
    "\n",
    "                chat_input  = gr.MultimodalTextbox(\n",
    "                    interactive=True,\n",
    "                    file_count=\"multiple\",\n",
    "                    placeholder=\"Ask me a question\",\n",
    "                    container=False,\n",
    "                    scale=7,\n",
    "                    show_label=False,\n",
    "                    sources=[\"microphone\", \"upload\"],\n",
    "                )\n",
    "\n",
    "                chat_msg = chat_input.submit(\n",
    "                    add_message, \n",
    "                    [chatbot, chat_input], \n",
    "                    [chatbot, chat_input]\n",
    "                )\n",
    "                bot_msg = chat_msg.then(bot_output, chatbot, chatbot, api_name=\"bot_response\")\n",
    "                bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "                chatbot.like(print_like_dislike, None, None)\n",
    "                chatbot.undo(handle_undo, chatbot, [chatbot, chat_input])\n",
    "    return blocks\n",
    "\n",
    "def create_ui():\n",
    "    with gr.Blocks() as interface:\n",
    "        with gr.Tab('Chat', id='Chat', elem_id='chat-tab'):\n",
    "            create_chat_ui()\n",
    "        with gr.Tab('Chat1', id='Chat1', elem_id='tab'):\n",
    "            gr.Markdown(\"Chat1\")\n",
    "        \n",
    "    return interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_ui()\n",
    "    demo.launch(show_error=True, show_api=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 17:45:51,685 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-01 17:45:51,697 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py:1017: UserWarning: Expected 1 arguments for function <function <lambda> at 0x000001F48337C310>, received 0.\n",
      "  warnings.warn(\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py:1021: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x000001F48337C310>, received 0.\n",
      "  warnings.warn(\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py:1017: UserWarning: Expected 1 arguments for function <function <lambda> at 0x000001F48337D900>, received 0.\n",
      "  warnings.warn(\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\utils.py:1021: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x000001F48337D900>, received 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Block.render() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 83\u001B[0m\n\u001B[0;32m     76\u001B[0m                     btn\u001B[38;5;241m.\u001B[39mclick(\n\u001B[0;32m     77\u001B[0m                         fn\u001B[38;5;241m=\u001B[39mpartial(load_chat, chat_id\u001B[38;5;241m=\u001B[39mcid, chat_histories\u001B[38;5;241m=\u001B[39mchat_histories),\n\u001B[0;32m     78\u001B[0m                         inputs\u001B[38;5;241m=\u001B[39m[],  \u001B[38;5;66;03m# No additional inputs needed.\u001B[39;00m\n\u001B[0;32m     79\u001B[0m                         outputs\u001B[38;5;241m=\u001B[39m[chatbot_display, chat_id_input]\n\u001B[0;32m     80\u001B[0m                     )\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# Place the dynamic buttons container in the layout.\u001B[39;00m\n\u001B[1;32m---> 83\u001B[0m     \u001B[43mchat_buttons_container\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrender_buttons\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m demo\u001B[38;5;241m.\u001B[39mlaunch()\n",
      "\u001B[1;31mTypeError\u001B[0m: Block.render() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 17:45:52,101 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n",
      "2025-02-01 17:45:52,113 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F483752200>\n",
      "2025-02-01 17:45:52,114 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F4FFD00DC0> server_hostname='api.gradio.app' timeout=3\n",
      "2025-02-01 17:45:52,564 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F480161C30>\n",
      "2025-02-01 17:45:52,565 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-01 17:45:52,566 - DEBUG - send_request_headers.complete\n",
      "2025-02-01 17:45:52,568 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-01 17:45:52,569 - DEBUG - send_request_body.complete\n",
      "2025-02-01 17:45:52,570 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-01 17:45:52,782 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 01 Feb 2025 15:45:53 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-02-01 17:45:52,783 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-01 17:45:52,785 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-01 17:45:52,786 - DEBUG - receive_response_body.complete\n",
      "2025-02-01 17:45:52,788 - DEBUG - response_closed.started\n",
      "2025-02-01 17:45:52,790 - DEBUG - response_closed.complete\n",
      "2025-02-01 17:45:52,792 - DEBUG - close.started\n",
      "2025-02-01 17:45:52,794 - DEBUG - close.complete\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from functools import partial\n",
    "\n",
    "def process_message(chat_histories, chat_id, message):\n",
    "    \"\"\"\n",
    "    Add the new message (and a simple bot reply) to the chat history for the provided chat_id.\n",
    "    \"\"\"\n",
    "    if chat_id not in chat_histories:\n",
    "        chat_histories[chat_id] = []\n",
    "    # For demonstration, the bot responds with the reversed message.\n",
    "    bot_response = f\"Bot: {message[::-1]}\"\n",
    "    chat_histories[chat_id].append((f\"You: {message}\", bot_response))\n",
    "    # Return updated chat histories and the conversation for the active chat.\n",
    "    return chat_histories, chat_histories[chat_id]\n",
    "\n",
    "def load_chat(chat_id, chat_histories):\n",
    "    \"\"\"\n",
    "    Return the chat history for a given chat_id.\n",
    "    \"\"\"\n",
    "    return chat_histories.get(chat_id, []), chat_id\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Chatbot with Dynamic Chat History Buttons\")\n",
    "    \n",
    "    # State variable to hold all chat histories as a dictionary:\n",
    "    #   { chat_id: [ (user message, bot response), ... ] }\n",
    "    chat_histories_state = gr.State({})\n",
    "    \n",
    "    with gr.Row():\n",
    "        chat_id_input = gr.Textbox(\n",
    "            label=\"Chat Session ID\",\n",
    "            placeholder=\"Enter a unique chat ID (e.g., user1)\"\n",
    "        )\n",
    "        user_message = gr.Textbox(\n",
    "            label=\"Your Message\",\n",
    "            placeholder=\"Type your message here\"\n",
    "        )\n",
    "        send_btn = gr.Button(\"Send\")\n",
    "    \n",
    "    # Chatbot display that shows the current conversation.\n",
    "    chatbot_display = gr.Chatbot(label=\"Conversation\")\n",
    "    \n",
    "    # A container where the dynamic chat buttons will be rendered.\n",
    "    chat_buttons_container = gr.Column()\n",
    "    \n",
    "    # When the Send button is clicked, process the new message.\n",
    "    send_btn.click(\n",
    "        process_message,\n",
    "        inputs=[chat_histories_state, chat_id_input, user_message],\n",
    "        outputs=[chat_histories_state, chatbot_display]\n",
    "    ).then(\n",
    "        # Then re-render the dynamic buttons using our render_buttons function.\n",
    "        lambda state: state,  # Pass through the state (dummy function)\n",
    "        outputs=[]  # No direct outputs here.\n",
    "    ).then(\n",
    "        # Now update the dynamic buttons.\n",
    "        lambda state: state,  # Again, pass through\n",
    "        outputs=[]  # We just trigger a state change to update our render.\n",
    "    )\n",
    "    \n",
    "    # ---\n",
    "    # The dynamic rendering function: whenever chat_histories_state changes,\n",
    "    # this function re-renders the buttons.\n",
    "    @gr.render(inputs=chat_histories_state)\n",
    "    def render_buttons(chat_histories):\n",
    "        with gr.Column() as container:\n",
    "            # If there are no chat sessions yet, display a message.\n",
    "            if not chat_histories:\n",
    "                gr.Markdown(\"### No chats available\")\n",
    "            else:\n",
    "                # For each chat session, create a button.\n",
    "                for cid in chat_histories.keys():\n",
    "                    btn = gr.Button(f\"Chat: {cid}\", key=cid)\n",
    "                    # When this button is clicked, load that chat's history.\n",
    "                    # We use functools.partial to bind the current chat ID.\n",
    "                    btn.click(\n",
    "                        fn=partial(load_chat, chat_id=cid, chat_histories=chat_histories),\n",
    "                        inputs=[],  # No additional inputs needed.\n",
    "                        outputs=[chatbot_display, chat_id_input]\n",
    "                    )\n",
    "        return container\n",
    "\n",
    "    # Place the dynamic buttons container in the layout.\n",
    "    chat_buttons_container.render(render_buttons, chat_histories_state)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 16:19:29,113 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-03 16:19:29,130 - DEBUG - connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "2025-02-03 16:19:29,460 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n",
      "2025-02-03 16:19:29,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170D00EC20>\n",
      "2025-02-03 16:19:29,533 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021776F2DC40> server_hostname='api.gradio.app' timeout=3\n",
      "2025-02-03 16:19:29,744 - DEBUG - Using selector: SelectSelector\n",
      "2025-02-03 16:19:29,765 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=None socket_options=None\n",
      "2025-02-03 16:19:29,767 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170E7E5F90>\n",
      "2025-02-03 16:19:29,769 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,770 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:29,772 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,773 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:29,773 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,774 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Mon, 03 Feb 2025 14:19:29 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "2025-02-03 16:19:29,775 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:29,776 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,778 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:29,779 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:29,782 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:29,783 - DEBUG - close.started\n",
      "2025-02-03 16:19:29,785 - DEBUG - close.complete\n",
      "2025-02-03 16:19:29,787 - DEBUG - connect_tcp.started host='127.0.0.1' port=7860 local_address=None timeout=3 socket_options=None\n",
      "2025-02-03 16:19:29,789 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002170E802860>\n",
      "2025-02-03 16:19:29,790 - DEBUG - send_request_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:29,792 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:29,794 - DEBUG - send_request_body.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:29,795 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:29,807 - DEBUG - receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:29,809 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Mon, 03 Feb 2025 14:19:29 GMT'), (b'server', b'uvicorn'), (b'content-length', b'39787'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "2025-02-03 16:19:29,810 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:29,811 - DEBUG - receive_response_body.started request=<Request [b'HEAD']>\n",
      "2025-02-03 16:19:29,811 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:29,813 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:29,814 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:29,816 - DEBUG - close.started\n",
      "2025-02-03 16:19:29,817 - DEBUG - close.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 16:19:29,825 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-03 16:19:29,968 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002177D2FA8C0>\n",
      "2025-02-03 16:19:29,970 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,970 - DEBUG - send_request_headers.complete\n",
      "2025-02-03 16:19:29,973 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:29,974 - DEBUG - send_request_body.complete\n",
      "2025-02-03 16:19:29,975 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:30,050 - DEBUG - https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/1.1\" 200 0\n",
      "2025-02-03 16:19:30,181 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 03 Feb 2025 14:19:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "2025-02-03 16:19:30,182 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-02-03 16:19:30,186 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-03 16:19:30,188 - DEBUG - receive_response_body.complete\n",
      "2025-02-03 16:19:30,190 - DEBUG - response_closed.started\n",
      "2025-02-03 16:19:30,193 - DEBUG - response_closed.complete\n",
      "2025-02-03 16:19:30,196 - DEBUG - close.started\n",
      "2025-02-03 16:19:30,198 - DEBUG - close.complete\n",
      "q:\\miniAnaconda\\envs\\ml\\lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import inspect\n",
    "from gradio.components.multimodal_textbox import MultimodalPostprocess\n",
    "from typing import Literal, Union, cast\n",
    "import anyio\n",
    "import copy\n",
    "import dataclasses\n",
    "from gradio import utils\n",
    "from gradio.helpers import special_args\n",
    "from collections.abc import AsyncGenerator\n",
    "from gradio.components.chatbot import (\n",
    "    ChatMessage,\n",
    "    Message,\n",
    "    MessageDict,\n",
    "    TupleFormat,\n",
    ")\n",
    "multimodal = True\n",
    "limiter = None\n",
    "\n",
    "############################################################\n",
    "############### Bussines Logic #############################\n",
    "############################################################\n",
    "\n",
    "def bot_output(_unused, history: list):\n",
    "    try:\n",
    "        history.append(gr.ChatMessage(role=\"assistant\", content=\"\"))\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            history,    # [msg.dict() for msg in history]\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        model_inputs  = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "        generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "        generated_text  = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        if not generated_text or not isinstance(generated_text, str):  \n",
    "            generated_text = \"I'm sorry, but I couldn't generate a response.\"\n",
    "\n",
    "        for char in generated_text :\n",
    "            history[-1].content += char\n",
    "            sleep(0.01) \n",
    "            yield history\n",
    "\n",
    "    \n",
    "        yield history\n",
    "\n",
    "    except Exception as e:\n",
    "        history.append(gr.ChatMessage(role=\"system\", content=f\"Failed to create text: {str(e)}\"))\n",
    "        yield history\n",
    "        raise gr.Error(f\"Failed to create text: {str(e)}\")\n",
    "\n",
    "fn = bot_output\n",
    "############################################################\n",
    "############### Inner Logic ################################\n",
    "############################################################\n",
    "\n",
    "def save_conversation(index: int | None, conversation: list[gr.MessageDict], saved_conversations: list[list[gr.MessageDict]]):\n",
    "    if index is not None:\n",
    "        saved_conversations[index] = conversation\n",
    "    else:\n",
    "        saved_conversations.append(conversation)\n",
    "        index = len(saved_conversations) - 1\n",
    "    return index, saved_conversations\n",
    "\n",
    "def delete_conversation(index: int | None, saved_conversations: list[list[gr.MessageDict]]):\n",
    "\n",
    "    if index is not None:\n",
    "        saved_conversations.pop(index)\n",
    "    return None, saved_conversations\n",
    "\n",
    "def generate_chat_title(conversation: list[gr.MessageDict]) -> str:\n",
    "        \"\"\"\n",
    "        Generate a title for a conversation by taking the first user message that is a string\n",
    "        and truncating it to 40 characters. If files are present, add a üìé to the title.\n",
    "        \"\"\"\n",
    "        title = \"\"\n",
    "        for message in conversation:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                if isinstance(message[\"content\"], str):\n",
    "                    title += message[\"content\"]\n",
    "                    break\n",
    "                else:\n",
    "                    title += \"üìé \"\n",
    "        if len(title) > 40:\n",
    "            title = title[:40] + \"...\"\n",
    "        return title or \"Conversation\"\n",
    "\n",
    "def load_conversation(index: int, conversations: list[list[gr.MessageDict]]):\n",
    "    return (\n",
    "        index,\n",
    "        gr.Chatbot(\n",
    "            value=conversations[index],  # type: ignore\n",
    "            feedback_value=[],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def load_chat_history(conversations):\n",
    "        return gr.Dataset(\n",
    "            samples=[\n",
    "                [generate_chat_title(conv)]\n",
    "                for conv in conversations or []\n",
    "                if conv\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def clear_and_save_textbox(\n",
    "        message: str | MultimodalPostprocess,\n",
    "    ) -> tuple[\n",
    "        gr.Textbox | gr.MultimodalTextbox,\n",
    "        str | MultimodalPostprocess,\n",
    "    ]:\n",
    "        return (\n",
    "            type(chat_input)(\"\", interactive=False, placeholder=\"\"),\n",
    "            message,\n",
    "        )\n",
    "\n",
    "@staticmethod\n",
    "def messages_to_tuples(history_messages: list[gr.MessageDict]) -> TupleFormat:\n",
    "    history_tuples = []\n",
    "    for message in history_messages:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            history_tuples.append((message[\"content\"], None))\n",
    "        elif history_tuples and history_tuples[-1][1] is None:\n",
    "            history_tuples[-1] = (history_tuples[-1][0], message[\"content\"])\n",
    "        else:\n",
    "            history_tuples.append((None, message[\"content\"]))\n",
    "    return history_tuples\n",
    "\n",
    "@staticmethod\n",
    "def tuples_to_messages(history_tuples: TupleFormat) -> list[MessageDict]:\n",
    "    history_messages = []\n",
    "    for message_tuple in history_tuples:\n",
    "        if message_tuple[0]:\n",
    "            history_messages.append({\"role\": \"user\", \"content\": message_tuple[0]})\n",
    "        if message_tuple[1]:\n",
    "            history_messages.append(\n",
    "                {\"role\": \"assistant\", \"content\": message_tuple[1]}\n",
    "            )\n",
    "    return history_messages\n",
    "\n",
    "def message_as_message_dict(\n",
    "        message: gr.MessageDict | Message | str | gr.Component | MultimodalPostprocess | list,\n",
    "        role: Literal[\"user\", \"assistant\"],\n",
    "    ) -> list[MessageDict]:\n",
    "        \"\"\"\n",
    "        Converts a user message, example message, or response from the chat function to a\n",
    "        list of MessageDict objects that can be appended to the chat history.\n",
    "        \"\"\"\n",
    "        message_dicts = []\n",
    "        if not isinstance(message, list):\n",
    "            message = [message]\n",
    "        for msg in message:\n",
    "            if isinstance(msg, Message):\n",
    "                message_dicts.append(msg.model_dump())\n",
    "            elif isinstance(msg, ChatMessage):\n",
    "                msg.role = role\n",
    "                message_dicts.append(\n",
    "                    dataclasses.asdict(msg, dict_factory=utils.dict_factory)\n",
    "                )\n",
    "            elif isinstance(msg, (str, gr.Component)):\n",
    "                message_dicts.append({\"role\": role, \"content\": msg})\n",
    "            elif (\n",
    "                isinstance(msg, dict) and \"content\" in msg\n",
    "            ):  # in MessageDict format already\n",
    "                msg[\"role\"] = role\n",
    "                message_dicts.append(msg)\n",
    "            else:  # in MultimodalPostprocess format\n",
    "                for x in msg.get(\"files\", []):\n",
    "                    if isinstance(x, dict):\n",
    "                        x = x.get(\"path\")\n",
    "                    message_dicts.append({\"role\": role, \"content\": (x,)})\n",
    "                if msg[\"text\"] is None or not isinstance(msg[\"text\"], str):\n",
    "                    pass\n",
    "                else:\n",
    "                    message_dicts.append({\"role\": role, \"content\": msg[\"text\"]})\n",
    "        return message_dicts\n",
    "\n",
    "def append_message_to_history(\n",
    "        message: gr.MessageDict | Message | str | gr.Component | MultimodalPostprocess | list,\n",
    "        history: list[gr.MessageDict] | TupleFormat,\n",
    "        role: Literal[\"user\", \"assistant\"] = \"user\",\n",
    "    ) -> list[gr.MessageDict] | TupleFormat:\n",
    "        message_dicts = message_as_message_dict(message, role)\n",
    "        if type == \"tuples\":\n",
    "            history = tuples_to_messages(history)  # type: ignore\n",
    "        else:\n",
    "            history = copy.deepcopy(history)\n",
    "        history.extend(message_dicts)  # type: ignore\n",
    "        if type == \"tuples\":\n",
    "            history = messages_to_tuples(history)  # type: ignore\n",
    "        return history\n",
    "\n",
    "def pop_last_user_message(\n",
    "        history: list[MessageDict] | TupleFormat,\n",
    "    ) -> tuple[list[MessageDict] | TupleFormat, str | MultimodalPostprocess]:\n",
    "        \"\"\"\n",
    "        Removes the message (or set of messages) that the user last sent from the chat history and returns them.\n",
    "        If self.multimodal is True, returns a MultimodalPostprocess (dict) object with text and files.\n",
    "        If self.multimodal is False, returns just the message text as a string.\n",
    "        \"\"\"\n",
    "        if not history:\n",
    "            return history, \"\" if not multimodal else {\"text\": \"\", \"files\": []}\n",
    "\n",
    "        if type == \"tuples\":\n",
    "            history = tuples_to_messages(history)  # type: ignore\n",
    "        i = len(history) - 1\n",
    "        while i >= 0 and history[i][\"role\"] == \"assistant\":  # type: ignore\n",
    "            i -= 1\n",
    "        while i >= 0 and history[i][\"role\"] == \"user\":  # type: ignore\n",
    "            i -= 1\n",
    "        last_messages = history[i + 1 :]\n",
    "        last_user_message = \"\"\n",
    "        files = []\n",
    "        for msg in last_messages:\n",
    "            assert isinstance(msg, dict)  # noqa: S101\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                content = msg[\"content\"]\n",
    "                if isinstance(content, tuple):\n",
    "                    files.append(content[0])\n",
    "                else:\n",
    "                    last_user_message = content\n",
    "        return_message = (\n",
    "            {\"text\": last_user_message, \"files\": files}\n",
    "            if multimodal\n",
    "            else last_user_message\n",
    "        )\n",
    "        history_ = history[: i + 1]\n",
    "        if type == \"tuples\":\n",
    "            history_ = messages_to_tuples(history_)  # type: ignore\n",
    "        return history_, return_message  # type: ignore\n",
    "\n",
    "\n",
    "async def submit_fn(message: str | MultimodalPostprocess, history: TupleFormat | list[MessageDict], request: gr.Request, *args,\n",
    ") -> tuple:\n",
    "    inputs, _, _ = special_args(\n",
    "        fn, inputs=[message, history, *args], request=request\n",
    "    )\n",
    "    if is_async:\n",
    "        response = await fn(*inputs)\n",
    "    else:\n",
    "        response = await anyio.to_thread.run_sync(\n",
    "            fn, *inputs, limiter=limiter\n",
    "        )\n",
    "    if additional_outputs:\n",
    "        response, *additional_outputs = response\n",
    "    else:\n",
    "        additional_outputs = None\n",
    "    history = append_message_to_history(message, history, \"user\")\n",
    "    history = append_message_to_history(response, history, \"assistant\")\n",
    "    if additional_outputs:\n",
    "        return response, history, *additional_outputs\n",
    "    return response, history\n",
    "\n",
    "async def stream_fn(message: str | MultimodalPostprocess, history: TupleFormat | list[MessageDict], request: gr.Request, *args,\n",
    ") -> AsyncGenerator[\n",
    "    tuple,\n",
    "    None,\n",
    "]:\n",
    "    inputs, _, _ = special_args(\n",
    "        fn, inputs=[message, history, *args], request=request\n",
    "    )\n",
    "    if is_async:\n",
    "        generator = fn(*inputs)\n",
    "    else:\n",
    "        generator = await anyio.to_thread.run_sync(\n",
    "            fn, *inputs, limiter=limiter\n",
    "        )\n",
    "        generator = utils.SyncToAsyncIterator(generator, limiter)\n",
    "\n",
    "    history = append_message_to_history(message, history, \"user\")\n",
    "    additional_outputs = None\n",
    "    try:\n",
    "        first_response = await utils.async_iteration(generator)\n",
    "        if additional_outputs:\n",
    "            first_response, *additional_outputs = first_response\n",
    "        history_ = append_message_to_history(\n",
    "            first_response, history, \"assistant\"\n",
    "        )\n",
    "        if not additional_outputs:\n",
    "            yield first_response, history_\n",
    "        else:\n",
    "            yield first_response, history_, *additional_outputs\n",
    "    except StopIteration:\n",
    "        yield None, history\n",
    "    async for response in generator:\n",
    "        if additional_outputs:\n",
    "            response, *additional_outputs = response\n",
    "        history_ = append_message_to_history(response, history, \"assistant\")\n",
    "        if not additional_outputs:\n",
    "            yield response, history_\n",
    "        else:\n",
    "            yield response, history_, *additional_outputs\n",
    "\n",
    "def edit_message(history: list[MessageDict] | TupleFormat, edit_data: gr.EditData) -> tuple[\n",
    "        list[MessageDict] | TupleFormat,\n",
    "        list[MessageDict] | TupleFormat,\n",
    "        str | MultimodalPostprocess,\n",
    "    ]:\n",
    "        if isinstance(edit_data.index, (list, tuple)):\n",
    "            history = history[: edit_data.index[0]]\n",
    "        else:\n",
    "            history = history[: edit_data.index]\n",
    "        return history, history, edit_data.value\n",
    "\n",
    "############################################################\n",
    "############### UI Logic from ChatInterface ################\n",
    "############################################################\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, min_width=100):\n",
    "            \n",
    "            new_chat_button = gr.Button(\n",
    "                \"New chat\",\n",
    "                variant=\"primary\",\n",
    "                size=\"md\",\n",
    "            )\n",
    "            chat_history_dataset = gr.Dataset(\n",
    "                components=[gr.Textbox(visible=False)],\n",
    "                show_label=False,\n",
    "                layout=\"table\",\n",
    "                type=\"index\",\n",
    "            )\n",
    "\n",
    "        with gr.Column(scale=5):\n",
    "            chatbot = gr.Chatbot(elem_id=\"chatbot\", \n",
    "                height=500,\n",
    "                type=\"messages\",\n",
    "                placeholder=f\"<strong><br><big>JARvis</strong>\",\n",
    "                editable=True\n",
    "            )\n",
    "            chat_input = gr.MultimodalTextbox(\n",
    "                interactive=True,\n",
    "                file_count=\"multiple\",\n",
    "                container=False,\n",
    "                show_label=False,\n",
    "                placeholder=\"Ask me a question\",\n",
    "                sources=[\"microphone\", \"upload\"],\n",
    "            )\n",
    "\n",
    "        chatbot_state = gr.State(chatbot.value if chatbot.value else [])\n",
    "        chatbot_value = gr.State(chatbot.value if chatbot.value else [])\n",
    "        null_component = gr.State()\n",
    "        is_generator = inspect.isgeneratorfunction(\n",
    "            fn\n",
    "        ) or inspect.isasyncgenfunction(fn)\n",
    "        is_async = inspect.iscoroutinefunction(\n",
    "            fn\n",
    "        ) or inspect.isasyncgenfunction(fn)\n",
    "        submit_fn = stream_fn if is_generator else submit_fn\n",
    "\n",
    "        saved_conversations = gr.BrowserState(\n",
    "                [], storage_key=f\"saved_conversations_{id}\"\n",
    "            )\n",
    "        conversation_id = gr.State(None)\n",
    "        saved_input = gr.State() \n",
    "        synchronize_chat_state_kwargs = {\n",
    "                    \"fn\": lambda x: (x, x),\n",
    "                    \"inputs\": [chatbot],\n",
    "                    \"outputs\": [chatbot_state, chatbot_value],\n",
    "                    \"show_api\": False,\n",
    "                    \"queue\": False,\n",
    "                }\n",
    "        save_fn_kwargs = {\n",
    "            \"fn\": save_conversation,\n",
    "            \"inputs\": [\n",
    "                conversation_id,\n",
    "                chatbot_state,\n",
    "                saved_conversations,\n",
    "            ],\n",
    "            \"outputs\": [conversation_id, saved_conversations],\n",
    "            \"show_api\": False,\n",
    "            \"queue\": False,\n",
    "        }\n",
    "        submit_fn_kwargs = {\n",
    "            \"fn\": submit_fn,\n",
    "            \"inputs\": [saved_input, chatbot_state],\n",
    "            \"outputs\": [null_component, chatbot],\n",
    "            \"show_api\": False,\n",
    "            \"concurrency_limit\": cast(\n",
    "                Union[int, Literal[\"default\"], None], 'default'\n",
    "            ),\n",
    "            \"show_progress\": cast(\n",
    "                Literal[\"full\", \"minimal\", \"hidden\"], 'full'\n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "        submit_event = (\n",
    "        chat_input.submit( \n",
    "            clear_and_save_textbox,\n",
    "            [chat_input],\n",
    "            [chat_input, saved_input],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        ).then(  # The reason we do this outside of the submit_fn is that we want to update the chatbot UI with the user message immediately, before the submit_fn is called\n",
    "                append_message_to_history,\n",
    "                [saved_input, chatbot],\n",
    "                [chatbot],\n",
    "                show_api=False,\n",
    "                queue=False,\n",
    "            ).then(**submit_fn_kwargs)\n",
    "        )\n",
    "        submit_event.then(**synchronize_chat_state_kwargs).then(\n",
    "            lambda: gr.update(value=None, interactive=True),\n",
    "            None,\n",
    "            chat_input,\n",
    "            show_api=False,\n",
    "        ).then(**save_fn_kwargs)\n",
    "\n",
    "        retry_event = (\n",
    "            chatbot.retry(\n",
    "                pop_last_user_message,\n",
    "                [chatbot_state],\n",
    "                [chatbot_state, saved_input],\n",
    "                show_api=False,\n",
    "                queue=False,\n",
    "            )\n",
    "            .then(\n",
    "                append_message_to_history,\n",
    "                [saved_input, chatbot_state],\n",
    "                [chatbot],\n",
    "                show_api=False,\n",
    "                queue=False,\n",
    "            )\n",
    "            .then(\n",
    "                lambda: gr.update(interactive=False, placeholder=\"\"),\n",
    "                outputs=[chat_input],\n",
    "                show_api=False,\n",
    "            ).then(**submit_fn_kwargs)\n",
    "        )\n",
    "        retry_event.then(**synchronize_chat_state_kwargs).then(\n",
    "            lambda: gr.update(interactive=True),\n",
    "            outputs=[chat_input],\n",
    "            show_api=False,\n",
    "        ).then(**save_fn_kwargs)\n",
    "\n",
    "\n",
    "        chatbot.undo(\n",
    "            pop_last_user_message,\n",
    "            [chatbot],\n",
    "            [chatbot, chat_input],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        ).then(**synchronize_chat_state_kwargs).then(**save_fn_kwargs)\n",
    "\n",
    "        chatbot.clear(**synchronize_chat_state_kwargs).then(\n",
    "            delete_conversation,\n",
    "            [conversation_id, saved_conversations],\n",
    "            [conversation_id, saved_conversations],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        )\n",
    "\n",
    "        new_chat_button.click(\n",
    "            lambda: (None, []),\n",
    "            None,\n",
    "            [conversation_id, chatbot],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        ).then(\n",
    "            lambda x: x,\n",
    "            [chatbot],\n",
    "            [chatbot_state],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        )\n",
    "\n",
    "        saved_conversations.change(\n",
    "            fn=load_chat_history,\n",
    "            inputs=[saved_conversations],\n",
    "            outputs=[chat_history_dataset],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "        )\n",
    "\n",
    "        chat_history_dataset.click(\n",
    "            lambda: [],\n",
    "            None,\n",
    "            [chatbot],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "            show_progress=\"hidden\",\n",
    "        ).then(\n",
    "            load_conversation,\n",
    "            [chat_history_dataset, saved_conversations],\n",
    "            [conversation_id, chatbot],\n",
    "            show_api=False,\n",
    "            queue=False,\n",
    "            show_progress=\"hidden\",\n",
    "        ).then(**synchronize_chat_state_kwargs)\n",
    "\n",
    "        if chatbot.editable:\n",
    "            chatbot.edit(\n",
    "                edit_message,\n",
    "                [chatbot],\n",
    "                [chatbot, chatbot_state, saved_input],\n",
    "                show_api=False,\n",
    "            ).success(**submit_fn_kwargs).success(**synchronize_chat_state_kwargs).then(\n",
    "                **save_fn_kwargs\n",
    "            )\n",
    "\n",
    "demo.launch(show_error=True, show_api=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptation from text-generation-webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "css = r\"src/static/static.css\"\n",
    "\n",
    "sidebar_html = r\"src/templates/main.html\"\n",
    "\n",
    "def create_chat_ui():\n",
    "    with gr.Blocks() as blocks:\n",
    "      gr.Chatbot(elem_id=\"chatbot\", \n",
    "          height=620,\n",
    "          type=\"messages\",\n",
    "          bubble_full_width=False,\n",
    "          placeholder=f\"<strong><br><big>JARvis</br></strong>\",\n",
    "          editable=True\n",
    "      )\n",
    "      gr.MultimodalTextbox(\n",
    "          interactive=True,\n",
    "          file_count=\"multiple\",\n",
    "          placeholder=\"Ask me a question\",\n",
    "          container=False,\n",
    "          scale=7,\n",
    "          show_label=False,\n",
    "          sources=[\"microphone\", \"upload\"],\n",
    "      )\n",
    "    return blocks\n",
    "\n",
    "def create_setting_ui():\n",
    "    with gr.Blocks() as blocks:\n",
    "       gr.Slider(minimum=0, maximum=100, label=\"Volume\")\n",
    "       gr.Slider(minimum=0, maximum=100, label=\"Brightness\")\n",
    "       gr.Slider(minimum=0, maximum=100, label=\"Contrast\")\n",
    "\n",
    "    return blocks\n",
    "\n",
    "def create_interface():\n",
    "  with gr.Blocks(css=css, theme=theme) as demo:\n",
    "    with gr.Row():\n",
    "      gr.HTML(sidebar_html)\n",
    "\n",
    "      with gr.Column(scale=8, elem_classes=\"main-content\"):\n",
    "        \n",
    "        with gr.Group(visible=True) as chat_group:\n",
    "          create_chat_ui()\n",
    "        \n",
    "        with gr.Group(visible=False) as settings_group:\n",
    "          create_setting_ui()\n",
    "\n",
    "      return demo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_interface()\n",
    "    demo.launch(show_error=True, show_api=True, debug=True)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:22:17.596189Z",
     "start_time": "2025-03-30T13:22:11.747346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "import torch\n",
    "from IPython.display import display, Audio\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "inputs = processor(text=\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "print(speech.numpy().shape)\n",
    "display(Audio(data=speech.numpy(), rate=15000))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.9843206e-04  4.6735961e-04  6.0230074e-04 ...  7.8680117e-05\n",
      " -8.1503400e-05 -3.1578346e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ],
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
